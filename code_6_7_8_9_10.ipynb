{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KiDY7o2dorP"
   },
   "outputs": [],
   "source": [
    "#code 6\n",
    "# installation  pip install billboard.py\n",
    "\n",
    "import billboard\n",
    "chart = billboard.ChartData('hot-100')\n",
    "\n",
    "filename = 'billboard_hot_100.csv'\n",
    "f = open(filename, 'w') # w = write\n",
    "headers = 'Song, Artist, Last Week, Peak Position, Weeks on Chart\\n'\n",
    "f.write(headers)\n",
    "\n",
    "for i in chart:\n",
    "    f.write(str(i.title.replace(\",\",\";\")))\n",
    "    f.write(\",\")\n",
    "    f.write(str(i.artist.replace(\",\",\";\")))\n",
    "    f.write(\",\")\n",
    "    f.write(str(i.lastPos))\n",
    "    f.write(\",\")\n",
    "    f.write(str(i.peakPos))\n",
    "    f.write(\",\")\n",
    "    f.write(str(i.weeks))\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    print(i.title, i.artist, i.lastPos, i.peakPos, i.weeks)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woAr82OAwJxQ"
   },
   "outputs": [],
   "source": [
    "# code 7\n",
    "from selenium import webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = \"S:/Program Files/Google/Chrome/Application/chrome.exe\"\n",
    "chrome_driver_binary = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(chrome_options=options)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "while True:\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//*[@id='block']\").click()\n",
    "        break\n",
    "    except:\n",
    "        print(\"Waiting for webpage\")\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/div/ul[1]/li[2]/a/div\").click()\n",
    "driver.switch_to.window(driver.window_handles[-3])\n",
    "driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input\").send_keys(\"Data science\")\n",
    "driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button\").click()\n",
    "\n",
    "\n",
    "name = driver.find_elements_by_xpath(\"//span[@class='fl ellipsis']\")\n",
    "pos  = driver.find_elements_by_xpath(\"//span[@class='ellipsis clr']\")\n",
    "com  = driver.find_elements_by_xpath(\"//a[@class='ellipsis']\")\n",
    "hirefor  = driver.find_elements_by_xpath(\"//div[@class='hireSec highlightable']\")\n",
    "loc  = driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "\n",
    "filename = 'naukri.com.csv'\n",
    "f = open(filename, 'w') # w = write\n",
    "headers = 'name, position, company, hirefor, location\\n'\n",
    "f.write(headers)\n",
    "\n",
    "start = 0\n",
    "start_2 = 1\n",
    "for i in range(0,50):\n",
    "    try:\n",
    "        f.write(com[start].text.replace(\",\",\";\"))\n",
    "        start+=2\n",
    "    except:\n",
    "        print(\"Missing\")\n",
    "        start+=2\n",
    "    f.write(\",\")\n",
    "    try:\n",
    "        f.write(pos[i].text.replace(\",\",\";\"))\n",
    "    except:\n",
    "        print(\"Missing\")\n",
    "    f.write(\",\")\n",
    "    try:\n",
    "        f.write(com[start_2].text.replace(\",\",\";\"))\n",
    "        start_2+=2\n",
    "    except:\n",
    "        print(\"Missing\")\n",
    "        start_2+=2\n",
    "    f.write(\",\")\n",
    "    try:\n",
    "        f.write(hirefor[i].text.replace(\",\",\";\"))\n",
    "    except:\n",
    "        print(\"Missing\")\n",
    "    f.write(\",\")\n",
    "    try:\n",
    "        f.write(loc[i].text.replace(\",\",\";\"))\n",
    "    except:\n",
    "        print(\"Missing\")\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Y9qMCwgbGVZ"
   },
   "outputs": [],
   "source": [
    "#code 8\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "dfs = pd.read_html(url)\n",
    "# Printing the table\n",
    "print(dfs[0])\n",
    "# Writing to a csv file.\n",
    "dfs[0].to_csv('Highest selling novels..csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEhOsrUGAHId"
   },
   "outputs": [],
   "source": [
    "#code 9\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = \"S:/Program Files/Google/Chrome/Application/chrome.exe\"\n",
    "chrome_driver_binary = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(chrome_options=options)\n",
    "\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "\n",
    "driver.get(url)\n",
    "while True:\n",
    "    try:\n",
    "        driver.find_element_by_class_name(\"vertical-ellipsis\").click()\n",
    "        driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[1]/div/div/div/div[2]/ul/li[2]/a\").click()\n",
    "        break\n",
    "    except:\n",
    "        print(\"Waiting for page to open.\")\n",
    "print(\"File is downloaded in the default download directory of your Chrome browser.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "aIy6oRifOc6S"
   },
   "outputs": [],
   "source": [
    "#code 10\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = \"S:/Program Files/Google/Chrome/Application/chrome.exe\"\n",
    "chrome_driver_binary = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(chrome_options=options)\n",
    "\n",
    "url = \"https://archive.ics.uci.edu\"\n",
    "driver.get(url)\n",
    "while True:\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a/font/b\").click()\n",
    "        break\n",
    "    except:\n",
    "        print(\"Waiting for page to open\")\n",
    "new_url = \"driver.current_url\"\n",
    "# Extract tables\n",
    "dfs = pd.read_html(new_url)\n",
    "# Fixing headers\n",
    "new_header = dfs[5].iloc[0]\n",
    "dfs[5] = dfs[5][1:]\n",
    "dfs[5].columns = new_header\n",
    "# Printing the table\n",
    "print(dfs[5])\n",
    "# Writing to a csv file.\n",
    "dfs[5].to_csv('UCIDatasets.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "code 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
