{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89bzE2w_w1ON"
   },
   "outputs": [],
   "source": [
    "# code 1\n",
    "import pandas as pd\n",
    "# Webpage url                                                                                                               \n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "# Extract tables\n",
    "dfs = pd.read_html(url)\n",
    "# deleting unnecessary columns.\n",
    "del dfs[0]['Note']\n",
    "del dfs[0]['Unnamed: 6']\n",
    "# Printing the table\n",
    "print(dfs[0].to_string(index=False))\n",
    "# Writing to a csv file.\n",
    "dfs[0].to_csv('mostViewedYoutubeVideos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oajU1ubrE5zj"
   },
   "outputs": [],
   "source": [
    "#code 2\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = \"S:/Program Files/Google/Chrome/Application/chrome.exe\"\n",
    "chrome_driver_binary = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(chrome_options=options)\n",
    "\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]\").click()\n",
    "driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]/div/ul/li[1]/a\").click()\n",
    "\n",
    "listMatch = driver.find_elements_by_class_name(\"event-list__list\")\n",
    "string = listMatch[0].text.split(\"\\n\")\n",
    "\n",
    "prefixes = ('January','February','March','April',\"May\",'June','July','August','September','October','November','December')\n",
    "\n",
    "newlist = [x for x in string if not x.startswith(prefixes)]\n",
    "\n",
    "filename = 'international fixture .csv'\n",
    "f = open(filename, 'w') # w = write\n",
    "headers = 'Match Title, Series, Place, Date, Time\\n'\n",
    "f.write(headers)\n",
    "for i in range(0,len(newlist),12):\n",
    "    print(newlist[i+6],newlist[i+5],newlist[i+7],newlist[i],newlist[i+1],newlist[i+2],newlist[i+3],newlist[i+8],newlist[i+9],newlist[i+10])\n",
    "    f.write(newlist[i+6].replace(\",\",\";\"))\n",
    "    f.write(\",\")\n",
    "    f.write(newlist[i+5].replace(\",\",\";\"))\n",
    "    f.write(\",\")\n",
    "    f.write(newlist[i+7].replace(\",\",\";\"))\n",
    "    f.write(\",\")\n",
    "    f.write(newlist[i].replace(\",\",\";\"))\n",
    "    f.write(\" \")\n",
    "    f.write(str(newlist[i+1]).replace(\",\",\";\"))\n",
    "    f.write(\" \")\n",
    "    f.write(newlist[i+2].replace(\",\",\";\"))\n",
    "    f.write(\",\")\n",
    "    f.write(newlist[i+3].replace(\",\",\";\"))\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pYymlN5zj2e"
   },
   "outputs": [],
   "source": [
    "# code 3.\n",
    "import pandas as pd\n",
    "# Webpage url                                                                                                               \n",
    "url = \"https://www.guru99.com/exception-handling-selenium.html\"\n",
    "# Extract tables\n",
    "dfs = pd.read_html(url)\n",
    "# Fixing headers\n",
    "new_header = dfs[0].iloc[0] \n",
    "dfs[0] = dfs[0][1:] \n",
    "dfs[0].columns = new_header\n",
    "# Printing the table\n",
    "print(dfs[0])\n",
    "# Writing to a csv file.\n",
    "dfs[0].to_csv('seleniumExceptions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88gQDYUU0uDr"
   },
   "outputs": [],
   "source": [
    "# code 4.\n",
    "import pandas as pd\n",
    "# Webpage url                                                                                                               \n",
    "url = \"http://statisticstimes.com/economy/gdp-of-indian-states.php\"\n",
    "# Extract tables\n",
    "dfs = pd.read_html(url)\n",
    "# Printing the table\n",
    "print(dfs[1])\n",
    "# Writing to a csv file.\n",
    "dfs[1].to_csv('IndiaStateWiseGdp.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11kTMen7TOJf"
   },
   "outputs": [],
   "source": [
    "# code 5.\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = \"S:/Program Files/Google/Chrome/Application/chrome.exe\"\n",
    "chrome_driver_binary = \"/usr/local/bin/chromedriver\"\n",
    "driver = webdriver.Chrome(chrome_options=options)\n",
    "\n",
    "url = \"https://github.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary\").click()\n",
    "        break\n",
    "    except:\n",
    "        print(\"Waiting for webpage\")\n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\").click()\n",
    "\n",
    "llist = driver.find_elements_by_xpath(\"//article[@class='Box-row']\")\n",
    "\n",
    "filename = 'GithubTrending.csv'\n",
    "f = open(filename, 'w') # w = write\n",
    "headers = 'Repository title, Repository description, Stars,  Language used\\n'\n",
    "f.write(headers)\n",
    "for i in range(0,len(llist)):\n",
    "    temp = llist[i].text.split(\"\\n\")\n",
    "    custom = temp[3].split(\" \")\n",
    "    if len(custom)>=5:\n",
    "        print(temp[1],temp[2],custom[1],custom[0])\n",
    "        f.write(str(temp[1]).replace(\",\",\";\"))\n",
    "        f.write(\",\")\n",
    "        f.write(str(temp[2].encode('utf-8')).replace(\",\",\";\"))\n",
    "        f.write(\",\")\n",
    "        f.write(str(custom[1]).replace(\",\",\"\"))\n",
    "        f.write(\",\")\n",
    "        f.write(str(custom[0]).replace(\",\",\";\"))\n",
    "        f.write(\"\\n\")\n",
    "    else:\n",
    "        print(temp[1],temp[2],custom[0],\"-------\")\n",
    "        f.write(str(temp[1]).replace(\",\",\";\"))\n",
    "        f.write(\",\")\n",
    "        f.write(str(temp[2].encode('utf-8')).replace(\",\",\";\"))\n",
    "        f.write(\",\")\n",
    "        f.write(str(custom[1]).replace(\",\",\"\"))\n",
    "        f.write(\",\")\n",
    "        f.write(\"Missing\")\n",
    "        f.write(\"\\n\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "code 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
